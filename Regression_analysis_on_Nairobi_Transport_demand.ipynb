{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishanu-Saha/data-science/blob/main/Regression_analysis_on_Nairobi_Transport_demand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. We are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "X-zAtxegW4JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from datetime import datetime\n",
        "import statsmodels.api as sm\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "sales_df = pd.read_csv('/content/drive/MyDrive/Almabetter /project/REGRESSION/Rossmann Stores Data.csv')\n",
        "stores_df = pd.read_csv('/content/drive/MyDrive/Almabetter /project/REGRESSION/store.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "sales_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores_df.head()"
      ],
      "metadata": {
        "id": "BsR34Z_dwhSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "sales_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores_df.shape"
      ],
      "metadata": {
        "id": "pnMIc5oQw5ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset contains 51645 rows and 10 columns "
      ],
      "metadata": {
        "id": "exjVM2nQX70u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stores_df.info()"
      ],
      "metadata": {
        "id": "nPsV5aTcxIgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have zero null values in every column.\n",
        "We need to convert seat_number , travel_date and travel_time from object to their respective data types."
      ],
      "metadata": {
        "id": "VNyDaGdkYJzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(stores_df[stores_df.duplicated()])"
      ],
      "metadata": {
        "id": "B5ptV7avx36R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have zero duplicate rows.Well thats a good sign!"
      ],
      "metadata": {
        "id": "4Gf3q1HjZMzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stores_df.isnull().sum()"
      ],
      "metadata": {
        "id": "wRGh8BLmyA1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling competition distance with the median value\n",
        "stores_df['CompetitionDistance'].fillna(stores_df['CompetitionDistance'].median(), inplace = True)\n",
        "     "
      ],
      "metadata": {
        "id": "W4T3fmLt0MHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling competition open since month and year with the most occuring values of the columns i.e modes of those columns\n",
        "stores_df['CompetitionOpenSinceMonth'].fillna(stores_df['CompetitionOpenSinceMonth'].mode()[0], inplace = True)\n",
        "stores_df['CompetitionOpenSinceYear'].fillna(stores_df['CompetitionOpenSinceYear'].mode()[0], inplace = True)"
      ],
      "metadata": {
        "id": "2kuYB4y90URY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imputing the nan values of promo2 related columns with 0\n",
        "stores_df['Promo2SinceWeek'].fillna(value=0,inplace=True)\n",
        "stores_df['Promo2SinceYear'].fillna(value=0,inplace=True)\n",
        "stores_df['PromoInterval'].fillna(value=0,inplace=True)\n",
        "     "
      ],
      "metadata": {
        "id": "Sb-jDPwA0tps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge the datasets on stores data\n",
        "df = sales_df.merge(right=stores_df, on=\"Store\", how=\"left\")\n",
        "     "
      ],
      "metadata": {
        "id": "SYrt8rKS09R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first five rows of the merged dataset\n",
        "df.head()\n",
        "     "
      ],
      "metadata": {
        "id": "hRZshLRJ1AsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#shape of the dataframe\n",
        "df.shape"
      ],
      "metadata": {
        "id": "3aNfD9td1Rgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datatypes\n",
        "df.info()"
      ],
      "metadata": {
        "id": "XSFGE4OB1S0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to change certain column datatypes .date ,Stateholiday"
      ],
      "metadata": {
        "id": "O_6i71fi2syB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "pQXb9o8CjpJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#change into int type\n",
        "df['StateHoliday'] = df['StateHoliday'].replace({'0':0,'a':1,'b':1,'c':1})"
      ],
      "metadata": {
        "id": "sIJLu2c15415"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "metadata": {
        "id": "DUo35vm33dkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#creating features from the date\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['WeekOfYear'] = df['Date'].dt.weekofyear\n",
        "df['DayOfYear'] = df['Date'].dt.dayofyear\n",
        "years = df['Year'].unique()\n",
        "years"
      ],
      "metadata": {
        "id": "S81EWmbK6yni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are given with the dataset which have 1017209 rows and 9 columns.Our target variable is 'Sales' column. we have zero duplicated or null rows."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "columns = list(df.columns)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "dGcIQFNrHc_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Id :Unique entry id\n",
        "\n",
        "Store :store_id\n",
        "\n",
        "Sales:Sales made for the day\n",
        "\n",
        "Customers: Footfall for the day\n",
        "\n",
        "Open: Open or closed\n",
        "\n",
        "StateHoliday: State Holiday or not\n",
        "\n",
        "SchoolHoliday: School Holiday or not\n",
        "\n",
        "Store: TypeType of stores\n",
        "\n",
        "Assortment :Type of assortment\n",
        "\n",
        "Competition :DistanceDistance from the nearest competition\n",
        "\n",
        "PromoStore :running promotion or not\n",
        "\n",
        "Promo2 :Store running consecutive promotion or not\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop all rows where \"Open\" is equal to zero\n",
        "data = df[df['Open'] != 0]"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by the Promo column and calculate the total number of customers for each Promo category\n",
        "customers_by_promo = data.groupby(['Promo'])['Customers'].sum().reset_index()\n",
        "\n",
        "# Create a bar plot with the Promo categories on the x-axis and the total number of customers on the y-axis\n",
        "plt.bar(customers_by_promo['Promo'], customers_by_promo['Customers'])\n",
        "plt.title('Total Customers by Promo')\n",
        "plt.xlabel('Promo')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "axQuJcfAfMBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers_by_promo"
      ],
      "metadata": {
        "id": "y_gvgUNqfXJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by the Promo column and calculate the total number of customers for each Promo category\n",
        "customers_by_promo = data.groupby(['StateHoliday'])['Customers'].sum().reset_index()\n",
        "\n",
        "# Create a bar plot with the Promo categories on the x-axis and the total number of customers on the y-axis\n",
        "plt.bar(customers_by_promo['StateHoliday'], customers_by_promo['Customers'])\n",
        "plt.title('Total Customers by StateHoliday')\n",
        "plt.xlabel('StateHoliday')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MWB2OKbOgVxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by the Promo column and calculate the total number of customers for each Promo category\n",
        "customers_by_promo = data.groupby(['SchoolHoliday'])['Customers'].sum().reset_index()\n",
        "\n",
        "# Create a bar plot with the Promo categories on the x-axis and the total number of customers on the y-axis\n",
        "plt.bar(customers_by_promo['SchoolHoliday'], customers_by_promo['Customers'])\n",
        "plt.title('Total Customers by SchoolHoliday')\n",
        "plt.xlabel('SchoolHoliday')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g0vCZwxMgWGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by the Promo column and calculate the total number of customers for each Promo category\n",
        "customers_by_promo = data.groupby(['StoreType'])['Customers'].sum().reset_index()\n",
        "\n",
        "# Create a bar plot with the Promo categories on the x-axis and the total number of customers on the y-axis\n",
        "plt.bar(customers_by_promo['StoreType'], customers_by_promo['Customers'])\n",
        "plt.title('Total Customers by StoreType')\n",
        "plt.xlabel('StoreType')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aHQtdao3gWaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by the Promo column and calculate the total number of customers for each Promo category\n",
        "customers_by_promo = data.groupby(['Assortment'])['Customers'].sum().reset_index()\n",
        "\n",
        "# Create a bar plot with the Promo categories on the x-axis and the total number of customers on the y-axis\n",
        "plt.bar(customers_by_promo['Assortment'], customers_by_promo['Customers'])\n",
        "plt.title('Total Customers by Assortment')\n",
        "plt.xlabel('Assortment')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TG2Jz51uf5qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of columns to plot\n",
        "col_count = ['DayOfWeek',  'Promo', 'StateHoliday', 'SchoolHoliday',\n",
        "             'StoreType', 'Assortment', 'CompetitionOpenSinceMonth',\n",
        "             'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
        "             'Promo2SinceYear', 'PromoInterval', 'Year', 'Month',\n",
        "             'WeekOfYear']\n",
        "\n",
        "# Create bar plots of the mean sales for each value in each column\n",
        "for col in col_count:\n",
        "    plt.figure(figsize=(12,6))\n",
        "    data.groupby(col)['Sales'].mean().plot(kind='bar')\n",
        "    plt.title('Mean Sales vs. ' + col)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Mean Sales')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mS_fiOhShRg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the counts of each store type\n",
        "store_counts = data['StoreType'].value_counts()\n",
        "\n",
        "# Create a pie chart using the store type counts\n",
        "plt.figure(figsize = (12,8))\n",
        "plt.pie(store_counts, labels=store_counts.index, autopct='%1.1f%%')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Store Types')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gL_IKRNLxGs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check the relationship between store type, assortment levels and sales\n",
        "sns.barplot(x=data[\"StoreType\"],y=data['Sales'],hue=df[\"Assortment\"])"
      ],
      "metadata": {
        "id": "VlwebWFSy27l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Year and Month columns into a single date column\n",
        "data['Date'] = pd.to_datetime(data['Year'].astype(str) + '-' + data['Month'].astype(str) + '-1')\n",
        "\n",
        "# Group the data by year and month and compute the total sales for each group\n",
        "sales_by_year_month = df.groupby(['Year', 'Month'])['Sales'].sum()\n",
        "\n",
        "# Create a figure and axis for the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# Loop through each year and plot the monthly sales as a line on the same axis\n",
        "for year in sales_by_year_month.index.levels[0]:\n",
        "    sales_by_month = sales_by_year_month.loc[year]\n",
        "    ax.plot(sales_by_month.index, sales_by_month.values, label=str(year))\n",
        "\n",
        "# Add axis labels and a legend to the plot\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_ylabel('Total Sales')\n",
        "ax.set_title('Monthly Sales Over Time by Year')\n",
        "ax.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6fDzuRv-YGaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns\n"
      ],
      "metadata": {
        "id": "a-pmtsENOUsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_columns = [ 'DayOfWeek', 'Sales', 'Customers',  'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Year', 'Month', 'WeekOfYear',  'DayOfYear']\n",
        "        \n",
        " # Create a correlation matrix of the numerical columns\n",
        "correlation_matrix = data[num_columns].corr()\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(correlation_matrix, annot=True)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Correlation Heatmap')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()      \n",
        "     "
      ],
      "metadata": {
        "id": "xqlVkgMqOiHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HYPOTHESIS TESTING "
      ],
      "metadata": {
        "id": "9y_BUE5TSMix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) The effect of promotions on sales: We are testing whether there is a significant difference in sales between days when there is a promotion versus days when there is no promotion.**\n",
        "\n",
        "Null hypothesis: There is no significant difference in sales between stores with and without a promotion.\n",
        "\n",
        "Alternative hypothesis: Stores with a promotion have significantly higher sales than stores without a promotion."
      ],
      "metadata": {
        "id": "4BXOMIObSWKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.copy()"
      ],
      "metadata": {
        "id": "pFjpOWFQVqf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Filter the data to include only days with promotions and non-promotions\n",
        "promo_sales = df[df['Promo']==1]['Sales']\n",
        "nonpromo_sales = df[df['Promo']==0]['Sales']\n",
        "\n",
        "# Test for difference in means using two-sample t-test\n",
        "t, p = stats.ttest_ind(promo_sales, nonpromo_sales, equal_var=False)\n",
        "print('t-value: {:.2f}, p-value: {:.4f}'.format(t, p))"
      ],
      "metadata": {
        "id": "taxkHKhfS8k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The effect of competition on sales: We are testing whether there is a significant correlation between the distance to the nearest competitor and sales.**\n",
        "\n",
        "Null hypothesis: There is no significant difference in sales between different store types.\n",
        "\n",
        "Alternative hypothesis: Some store types have significantly higher sales than others."
      ],
      "metadata": {
        "id": "YN3rOm0jUvdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Calculate the Pearson correlation coefficient and p-value between sales and competition distance\n",
        "corr, p = pearsonr(df['Sales'], df['CompetitionDistance'])\n",
        "print('Correlation coefficient: {:.2f}, p-value: {:.4f}'.format(corr, p))"
      ],
      "metadata": {
        "id": "DCakZnanPOeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The effect of store type on sales: You could test whether there is a significant difference in sales between different types of stores.**\n",
        "\n",
        "Null hypothesis: There is no significant relationship between competition distance and store sales.\n",
        "\n",
        "Alternative hypothesis: Stores located closer to competitors have significantly lower sales than stores located farther away."
      ],
      "metadata": {
        "id": "ns1MGbbaVKKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Filter the data to include only the three store types\n",
        "store_a_sales = df[df['StoreType']=='a']['Sales']\n",
        "store_b_sales = df[df['StoreType']=='b']['Sales']\n",
        "store_c_sales = df[df['StoreType']=='c']['Sales']\n",
        "\n",
        "# Test for difference in means using one-way ANOVA\n",
        "f, p = f_oneway(store_a_sales, store_b_sales, store_c_sales)\n",
        "print('F-value: {:.2f}, p-value: {:.4f}'.format(f, p))"
      ],
      "metadata": {
        "id": "j6BTi1GUVkNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Convert categorical variables to numerical using one-hot encoding\n",
        "df2 = data.copy()\n",
        "\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "ejuz3GvolGOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.columns "
      ],
      "metadata": {
        "id": "pG4dm7TkljpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lv85YBHCoyoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert CompetitionOpenSinceYear and CompetitionOpenSinceMonth to integers\n",
        "df2['CompetitionOpenSinceYear'] = df2['CompetitionOpenSinceYear'].astype(int)\n",
        "df2['CompetitionOpenSinceMonth'] = df2['CompetitionOpenSinceMonth'].astype(int)\n",
        "\n",
        "# Combine CompetitionOpenSinceYear and CompetitionOpenSinceMonth into a single feature\n",
        "df2['CompetitionOpenSince'] = pd.to_datetime(dict(year=df['CompetitionOpenSinceYear'], month=df['CompetitionOpenSinceMonth'], day=1))\n",
        "\n",
        "# Drop original columns\n",
        "df2.drop(['CompetitionOpenSinceYear', 'CompetitionOpenSinceMonth'], axis=1, inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code converts the CompetitionOpenSinceYear and CompetitionOpenSinceMonth columns to integers, then uses pd.to_datetime to combine them into a single column named CompetitionOpenSince as a datetime object. Finally, the original columns are dropped from the DataFrame using the drop method."
      ],
      "metadata": {
        "id": "XlD7mjGNrPo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#changing promo2 features into meaningful inputs\n",
        "#combining promo2 to total months\n",
        "df2['Promo2Open'] = (df2['Year'] - df2['Promo2SinceYear'])*12 + (df2['WeekOfYear'] - df2['Promo2SinceWeek'])*0.230137\n",
        "\n",
        "#correcting the neg values\n",
        "df2['Promo2Open'] = df2['Promo2Open'].apply(lambda x:0 if x < 0 else x)*df2['Promo2']\n",
        "\n",
        "#creating a feature for promo interval and checking if promo2 was running in the sale month\n",
        "def promo2running(df):\n",
        "  month_dict = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
        "  try:\n",
        "    months = df['PromoInterval'].split(',')\n",
        "    if df['Month'] and month_dict[df['Month']] in months:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  except Exception:\n",
        "    return 0\n",
        "\n",
        "#Applying \n",
        "df2['Promo2Active'] = df2.apply(promo2running,axis=1)*df2['Promo2']\n",
        "\n",
        "#Dropping unecessary columns\n",
        "df2.drop(['Promo2SinceYear','Promo2SinceWeek'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "CVuP6PALNfmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code above, we first convert the Promo2SinceWeek and Promo2SinceYear columns to a datetime format using the to_datetime function. We use a lambda function to combine these columns into a single string in ISO year-week format, which is then parsed using the format argument.\n",
        "\n",
        "We then create the Promo2Active feature by checking whether the store is running a Promo2 campaign, whether the Promo2 start date is less than or equal to the current date, and whether the current month is included in the PromoInterval. The resulting boolean value is then cast to an integer (1 for True, 0 for False).\n",
        "\n",
        "Finally, we drop the Promo2Since column since it is no longer needed."
      ],
      "metadata": {
        "id": "6psqFXJKrLDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a new feature called CompetitionDistanceGroup, which groups the CompetitionDistance into several bins, we can use the pandas cut() function.\n",
        "\n",
        "First, we can create a list of bin edges and labels that define the groupings. Here, let's use the edges [0, 500, 1500, 3000, 5000, np.inf] and the labels ['near', 'medium', 'far', 'very far', 'extreme'].\n",
        "\n",
        "Then, we can apply the cut() function to the CompetitionDistance column to create a new column called CompetitionDistanceGroup."
      ],
      "metadata": {
        "id": "6aB_cVmvq83K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bin edges and labels\n",
        "bin_edges = [0, 500, 1500, 3000, 5000, np.inf]\n",
        "bin_labels = ['near', 'medium', 'far', 'very far', 'extreme']\n",
        "\n",
        "# Create the CompetitionDistanceGroup column\n",
        "df2['CompetitionDistanceGroup'] = pd.cut(df2['CompetitionDistance'], bins=bin_edges, labels=bin_labels)\n",
        "\n",
        "# Show the first 5 rows of the new column\n",
        "print(df2[['CompetitionDistance', 'CompetitionDistanceGroup']].head())"
      ],
      "metadata": {
        "id": "jSDVYYUurApz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This will create a new column in the dataframe called 'AvgSalesPerCustomer', which will contain the average sales per customer for each store.\n",
        "df2['AvgSalesPerCustomer'] = df2['Sales'] / df2['Customers']"
      ],
      "metadata": {
        "id": "tz0EfP1Vqq_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "CeMwjh3WtqUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "corr_matrix = df2.corr()\n",
        "\n",
        "# Select the features with a correlation coefficient greater than 0.5\n",
        "high_corr_features = corr_matrix.index[abs(corr_matrix['Sales']) > 0.5]\n",
        "\n",
        "# Print the selected features\n",
        "print(high_corr_features)"
      ],
      "metadata": {
        "id": "G3BjAFGXc75o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since in correlation matrix only column customer is highly correlated with the Sales column.We have to select features from different method."
      ],
      "metadata": {
        "id": "NS7HVAFnc8_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection\n",
        "selected_features = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', 'CompetitionDistance', 'CompetitionOpenSince', 'Promo2Active', 'AvgSalesPerCustomer']\n",
        "\n",
        "# Create the feature matrix\n",
        "X = df2[selected_features].copy()\n",
        "\n",
        "# Convert StateHoliday to a categorical variable\n",
        "X['StateHoliday'] = X['StateHoliday'].astype('category')\n",
        "\n",
        "# Convert DayOfWeek to a categorical variable\n",
        "X['DayOfWeek'] = X['DayOfWeek'].astype('category')\n",
        "\n",
        "# Convert Promo2Active to a categorical variable\n",
        "X['Promo2Active'] = X['Promo2Active'].astype('category')\n",
        "\n",
        "# Convert CompetitionOpenSince to a datetime variable\n",
        "X['CompetitionOpenSince'] = pd.to_datetime(X['CompetitionOpenSince'], format='%Y-%m')\n",
        "\n",
        "# Extract the year and month of CompetitionOpenSince\n",
        "X['CompetitionOpenSinceYear'] = X['CompetitionOpenSince'].dt.year\n",
        "X['CompetitionOpenSinceMonth'] = X['CompetitionOpenSince'].dt.month\n",
        "\n",
        "# Remove the original CompetitionOpenSince column\n",
        "X = X.drop('CompetitionOpenSince', axis=1)\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Replace missing values with 0\n",
        "X = X.fillna(0)\n",
        "\n",
        "# Print the first 5 rows of the feature matrix\n",
        "print(X.head())"
      ],
      "metadata": {
        "id": "Um0qns1JQ7N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target variable \n",
        "Y = df2['Sales'].copy()"
      ],
      "metadata": {
        "id": "D9DdUXhiPt_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = sm.add_constant(X)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "F0cvybCXspzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = sm.OLS(y_train,x_train).fit()\n",
        "model_1.summary2()"
      ],
      "metadata": {
        "id": "GITm02xutUZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = X.copy()"
      ],
      "metadata": {
        "id": "Fm0-NYK8vPK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.info()"
      ],
      "metadata": {
        "id": "Vr1ADsEVz6zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CHECKING MULTICOLLINEARITY**"
      ],
      "metadata": {
        "id": "u1VJ2c0IvVwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def get_vif_factors(X):\n",
        "  X_matrix = X.to_numpy()\n",
        "  vif =  [variance_inflation_factor(X_matrix,i) for i in range(X_matrix.shape[1])]\n",
        "  vif_factors = pd.DataFrame()\n",
        "  vif_factors['column'] = X.columns\n",
        "  vif_factors['VIF'] = vif\n",
        "\n",
        "  return vif_factors"
      ],
      "metadata": {
        "id": "XYWwZWEDvfex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.columns\n",
        "features = ['Store', 'DayOfWeek', 'Date', 'Customers', 'Open', 'Promo',\n",
        "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
        "       'CompetitionDistance', 'Promo2', 'PromoInterval', 'Year', 'Month',\n",
        "       'WeekOfYear', 'DayOfYear', 'CompetitionOpenSince', 'Promo2Open',\n",
        "       'Promo2Active', 'CompetitionDistanceGroup', 'AvgSalesPerCustomer']"
      ],
      "metadata": {
        "id": "4NCTpXBHx6HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vif_factors = get_vif_factors(df3)\n",
        "vif_factors"
      ],
      "metadata": {
        "id": "27ZpIL3txVJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select the top 10 features based on f_regression test\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "selector = SelectKBest(f_regression, k=10)\n",
        "selector.fit(X, y)"
      ],
      "metadata": {
        "id": "PtE-JZxfP6rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the selected feature indices\n",
        "selected_features = selector.get_support(indices=True)\n",
        "selected_feature_names = X.columns[selected_features]\n",
        "selected_feature_names"
      ],
      "metadata": {
        "id": "1CXHx7oDTTqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**validating the selected features using appropriate evaluation metrics and cross-validation techniques to ensure that the model is not overfitting to the training data.**"
      ],
      "metadata": {
        "id": "iuXm39NZebVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# select the top 10 features\n",
        "X_selected = X[selected_feature_names]\n",
        "\n",
        "# perform 10-fold cross-validation with MAE metric\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "mae_scores = -cross_val_score(model, X_selected, y, cv=kfold, scoring='neg_mean_absolute_error')\n",
        "\n",
        "# calculate the mean and standard deviation of the MAE scores\n",
        "mae_mean = mae_scores.mean()\n",
        "mae_std = mae_scores.std()\n",
        "\n",
        "print(f'MAE: {mae_mean:.2f} +/- {mae_std:.2f}')"
      ],
      "metadata": {
        "id": "wjn4QGuyaiTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "model = sm.OLS(y,X_selected).fit()\n",
        "model.summary2()"
      ],
      "metadata": {
        "id": "0EveurNLpwdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A standard deviation of 6.83 for a mean absolute error of 2030.51 indicates that the model's performance may be somewhat variable across different test sets. "
      ],
      "metadata": {
        "id": "wmnoUGa8dh6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SelectKBest is a feature selection method in scikit-learn that selects the top k features based on univariate statistical tests.\n",
        "\n",
        "The k parameter in SelectKBest specifies the number of top features to select. The specific test used to score the features is specified by the score_func parameter, which takes a function that scores the features based on their relationship with the target variable.\n",
        "\n",
        "In this case, f_regression is used as the scoring function, which performs an analysis of variance (ANOVA) F-test to determine the strength of the linear relationship between each feature and the target variable. The get_support() method is used to return a Boolean mask indicating which of the features are selected.\n",
        "\n",
        "The selector.fit(X, y) method fits the feature selector to the data, using the specified input feature matrix X and target variable y.\n",
        "\n",
        "During the fitting process, the selector will evaluate each feature in X and assign a score based on its relevance to predicting the target variable. The score is computed using the specified metric or test, in this case f_regression.\n",
        "\n",
        "Once the scores are computed, the selector selects the top k features with the highest scores, where k is the number of features specified in the k parameter.\n",
        "\n",
        "Finally, the selector.get_support(indices=True) method returns an array of boolean values indicating which features were selected, where True represents a selected feature and False represents a non-selected feature. The indices=True parameter returns the indices of the selected features."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GbiJtegqcmia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5j4Cq7od0on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}