{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishanu-Saha/data-science/blob/main/Regression_analysis_on_Nairobi_Transport_demand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. We are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "X-zAtxegW4JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from datetime import datetime\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.graphics.regressionplots import influence_plot\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.graphics.regressionplots import plot_regress_exog\n",
        "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "sales_df = pd.read_csv('/content/drive/MyDrive/Almabetter /project/REGRESSION/Rossmann Stores Data.csv')\n",
        "stores_df = pd.read_csv('/content/drive/MyDrive/Almabetter /project/REGRESSION/store.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "sales_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores_df.head()"
      ],
      "metadata": {
        "id": "BsR34Z_dwhSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "sales_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores_df.shape"
      ],
      "metadata": {
        "id": "pnMIc5oQw5ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sales dataset contains 1017209 rows and 9 columns whereas stores dataset contains 1115 rows and 10 columns."
      ],
      "metadata": {
        "id": "JjlNiGYLOqF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.info()"
      ],
      "metadata": {
        "id": "zMRs9MNsPkym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stores_df.info()"
      ],
      "metadata": {
        "id": "nPsV5aTcxIgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of duplicated data\n",
        "len(stores_df[stores_df.duplicated()])"
      ],
      "metadata": {
        "id": "B5ptV7avx36R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sales_df[sales_df.duplicated()])"
      ],
      "metadata": {
        "id": "BjNSuyN5P4TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have zero duplicate rows.Well thats a good sign!"
      ],
      "metadata": {
        "id": "4Gf3q1HjZMzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking null values for every column\n",
        "stores_df.isnull().sum()"
      ],
      "metadata": {
        "id": "wRGh8BLmyA1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.isnull().sum()"
      ],
      "metadata": {
        "id": "_HpXoKCmQHJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Missing and Null Values\n"
      ],
      "metadata": {
        "id": "ETaklk-BH4fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filling competition distance with the median value\n",
        "stores_df['CompetitionDistance'].fillna(stores_df['CompetitionDistance'].median(), inplace = True)\n",
        "     "
      ],
      "metadata": {
        "id": "W4T3fmLt0MHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling competition open since month and year with the most occuring values of the columns i.e modes of those columns\n",
        "stores_df['CompetitionOpenSinceMonth'].fillna(stores_df['CompetitionOpenSinceMonth'].mode()[0], inplace = True)\n",
        "stores_df['CompetitionOpenSinceYear'].fillna(stores_df['CompetitionOpenSinceYear'].mode()[0], inplace = True)"
      ],
      "metadata": {
        "id": "2kuYB4y90URY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imputing the nan values of promo2 related columns with 0\n",
        "stores_df['Promo2SinceWeek'].fillna(value=0,inplace=True)\n",
        "stores_df['Promo2SinceYear'].fillna(value=0,inplace=True)\n",
        "stores_df['PromoInterval'].fillna(value=0,inplace=True)\n",
        "     "
      ],
      "metadata": {
        "id": "Sb-jDPwA0tps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge the datasets on stores data\n",
        "df = sales_df.merge(right=stores_df, on=\"Store\", how=\"left\")\n",
        "     "
      ],
      "metadata": {
        "id": "SYrt8rKS09R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first five rows of the merged dataset\n",
        "df.head()\n",
        "     "
      ],
      "metadata": {
        "id": "hRZshLRJ1AsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#shape of the dataframe\n",
        "df.shape"
      ],
      "metadata": {
        "id": "3aNfD9td1Rgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datatypes\n",
        "df.info()"
      ],
      "metadata": {
        "id": "XSFGE4OB1S0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to change certain column datatypes .date ,Stateholiday"
      ],
      "metadata": {
        "id": "O_6i71fi2syB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['StateHoliday'].unique()"
      ],
      "metadata": {
        "id": "KxYD1XAiRQxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to convert values to zero or one appropriately"
      ],
      "metadata": {
        "id": "LdRZTQ9nRa5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature engineering"
      ],
      "metadata": {
        "id": "CpcPU7g5IP2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#change into int type\n",
        "df['StateHoliday'] = df['StateHoliday'].replace({'0':0,'a':1,'b':1,'c':1})"
      ],
      "metadata": {
        "id": "sIJLu2c15415"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Date column into datetime datatype.\n",
        "df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "metadata": {
        "id": "DUo35vm33dkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#creating features from the date\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['WeekOfYear'] = df['Date'].dt.weekofyear\n",
        "df['DayOfYear'] = df['Date'].dt.dayofyear\n",
        "years = df['Year'].unique()\n",
        "years"
      ],
      "metadata": {
        "id": "S81EWmbK6yni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have obtained a dataset consisting of 1017209 rows and 22 columns. The target variable of our analysis is the 'Sales' column. The dataset is free of any duplicate entries or missing values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "columns = list(df.columns)\n",
        "columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "dGcIQFNrHc_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store: An integer value representing the unique identifier for each store in the dataset.\n",
        "\n",
        "DayOfWeek: An integer value representing the day of the week (1-7) when the sale was recorded.\n",
        "\n",
        "Date: A date value representing the date when the sale was recorded.\n",
        "\n",
        "Sales: A numerical value representing the amount of sales in a given day for a particular store.\n",
        "\n",
        "Customers: An integer value representing the number of customers who made purchases on a particular day at a particular store.\n",
        "\n",
        "Open: A binary value (0 or 1) indicating whether a store was open or closed on a given day.\n",
        "\n",
        "Promo: A binary value (0 or 1) indicating whether a store was running a promotional offer on a given day.\n",
        "\n",
        "StateHoliday: A categorical variable indicating the type of state holiday (if any) on a given day.\n",
        "\n",
        "SchoolHoliday: A binary value (0 or 1) indicating whether a school holiday was on a given day.\n",
        "\n",
        "StoreType: A categorical variable indicating the type of store.\n",
        "\n",
        "Assortment: A categorical variable indicating the level of assortment (i.e., range of products) offered by a store.\n",
        "\n",
        "CompetitionDistance: A numerical value representing the distance (in meters) to the nearest competitor store.\n",
        "\n",
        "CompetitionOpenSinceMonth: An integer value representing the month when the nearest competitor store opened.\n",
        "\n",
        "CompetitionOpenSinceYear: An integer value representing the year when the nearest competitor store opened.\n",
        "\n",
        "Promo2: A binary value (0 or 1) indicating whether a store is participating in a continuous promotional offer (i.e., Promo2).\n",
        "\n",
        "Promo2SinceWeek: An integer value representing the week when the store started participating in the continuous promotional offer (i.e., Promo2).\n",
        "\n",
        "Promo2SinceYear: An integer value representing the year when the store started participating in the continuous promotional offer (i.e., Promo2).\n",
        "\n",
        "PromoInterval: A categorical variable indicating the interval of continuous promotional offers, if any.\n",
        "\n",
        "Year: An integer value representing the year of the recorded sale.\n",
        "\n",
        "Month: An integer value representing the month of the recorded sale.\n",
        "\n",
        "WeekOfYear: An integer value representing the week of the year when the sale was recorded.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the observtion it seems that StateHoliday,StoreType,Assortment and PromoInterval are catagorical columns but we have to further investigate tthe StateHoiday column."
      ],
      "metadata": {
        "id": "ly79GVcmQeC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UNIVARIATE ANALYSIS"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop all rows where \"Open\" is equal to zero\n",
        "data = df[df['Open'] != 0]"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the counts of each store type\n",
        "store_counts = stores_df['StoreType'].value_counts()\n",
        "\n",
        "# Create a pie chart using the store type counts\n",
        "plt.figure(figsize = (12,8))\n",
        "plt.pie(store_counts, labels=store_counts.index, autopct='%1.1f%%')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Store Types')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gL_IKRNLxGs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "store A type : 54%\n",
        " \n",
        " store B type : 1.5%\n",
        " \n",
        " store C type : 13.3%\n",
        " \n",
        " store D type : 31.2%"
      ],
      "metadata": {
        "id": "yU8jIlSeWh_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the counts of each store type\n",
        "store_counts = stores_df['Assortment'].value_counts()\n",
        "\n",
        "# Create a pie chart using the store type counts\n",
        "plt.figure(figsize = (12,8))\n",
        "plt.pie(store_counts, labels=store_counts.index, autopct='%1.1f%%')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Assortment Types')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uh5Y4rvANjYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assortment type a : 53.2%\n",
        "Assortment type b : 0.8%\n",
        "Assortment type c : 46.0%\n"
      ],
      "metadata": {
        "id": "ueW9wgq_XeBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CUSTOMER ANALYSIS"
      ],
      "metadata": {
        "id": "6SCQ8vPjgHKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "UH8ZxwbgZLzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set the title and axis labels\n",
        "plt.figure(figsize = (20,20))\n",
        "\n",
        "# Create the barplot using seaborn\n",
        "plt.scatter(x = df['Customers'],y = df['Sales'])\n",
        "plt.title('Total Customers by Store')\n",
        "plt.xlabel('customers')\n",
        "plt.ylabel('sales')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g5FXwS2YZVX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can observe there is a direct relationship between customers and Sales , which is obvious more customers means more sales."
      ],
      "metadata": {
        "id": "QcqOAmUIhfPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aGMmLqlxaJkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot with the Promo categories on the x-axis and the total number of customers on the y-axis\n",
        "sns.barplot(x = 'Promo', y = 'Customers',data = df)\n",
        "plt.title('Mean Customers by Promo')\n",
        "plt.xlabel('Promo')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "axQuJcfAfMBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store which are promoting their stores has more customers than those who do not."
      ],
      "metadata": {
        "id": "Iwv9RvRejXag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot with the StateHoliday categories on the x-axis and the total number of customers on the y-axis\n",
        "sns.barplot(x = 'StateHoliday', y = 'Customers',data = df)\n",
        "plt.title('Mean Customers by StateHoliday')\n",
        "plt.xlabel('StateHoliday')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MWB2OKbOgVxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almost double Customers seems to come out more on when it is a Stateholiday."
      ],
      "metadata": {
        "id": "YZcpNxkXkOca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot with the SchoolHoliday categories on the x-axis and the total number of customers on the y-axis\n",
        "sns.barplot(x = 'SchoolHoliday', y = 'Customers',data = df)\n",
        "plt.title('Mean Customers by SchoolHoliday')\n",
        "plt.xlabel('SchoolHoliday')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g0vCZwxMgWGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customers are equally likely to come out on when it is a Schoolday."
      ],
      "metadata": {
        "id": "qgk0Hl7gk075"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot with the StoreType categories on the x-axis and the total number of customers on the y-axis\n",
        "sns.barplot(x = 'StoreType', y = 'Customers',data = df)\n",
        "plt.title('Mean Customers by StoreType')\n",
        "plt.xlabel('StoreType')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aHQtdao3gWaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean customers per StoreType in StoreType B is highest.It may indicate it is in demand or as from the pie chart B Type store are lesser in number thats why the high demand. "
      ],
      "metadata": {
        "id": "jF7c4IkEng0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot with the StoreType categories on the x-axis and the total number of customers on the y-axis\n",
        "sns.barplot(x = 'Assortment', y = 'Customers',data = df)\n",
        "plt.title('mean Customers by Assortment')\n",
        "plt.xlabel('Assortment')\n",
        "plt.ylabel('Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sb50Kd34mSLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stores which are of assortment type b are in huge demand since Mean Customers are highest in that category."
      ],
      "metadata": {
        "id": "AzR42LY-peQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of columns to plot\n",
        "col_count = ['DayOfWeek',  'Promo', 'StateHoliday', 'SchoolHoliday',\n",
        "             'StoreType', 'Assortment', 'CompetitionOpenSinceMonth',\n",
        "             'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
        "             'Promo2SinceYear', 'PromoInterval', 'Year', 'Month',\n",
        "             'WeekOfYear']\n",
        "\n",
        "# Create bar plots of the mean sales for each value in each column\n",
        "for col in col_count:\n",
        "    plt.figure(figsize=(12,6))\n",
        "    data.groupby(col)['Sales'].mean().plot(kind='bar')\n",
        "    plt.title('Mean Sales vs. ' + col)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Mean Sales')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mS_fiOhShRg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'DayOfWeek',  'Promo', 'StateHoliday', 'SchoolHoliday',\n",
        "             'StoreType', 'Assortment', 'CompetitionOpenSinceMonth',\n",
        "             'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
        "             'Promo2SinceYear', 'PromoInterval', 'Year', 'Month',\n",
        "             'WeekOfYear'"
      ],
      "metadata": {
        "id": "KByaJA7ysEXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 1 : Mean Sales vs Dayofweek** : Mean Sales are highest in day 1 and day 7 , and lowest in day 6 . This may indicate that people wait for the Hoilday to come and go for shopping. "
      ],
      "metadata": {
        "id": "mx7yUMFEq2uS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 2 : Mean Sales vs Promo** Means sales are higher when store owner promote their shops."
      ],
      "metadata": {
        "id": "f84H7M3gr0nW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 3 : Mean Sales vs StateHoliday** Mean Sales are higher when there is a sateholiday."
      ],
      "metadata": {
        "id": "R5g_xbsNsDTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 4 : Mean Sales vs StateHoliday** There isn't much difference in mean Sales regards to StateHoliday."
      ],
      "metadata": {
        "id": "ZAjlbrYtsJk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 5 : Mean Sales vs StoreType** Means Sales are highest in StoreType b ,it can result into greater yield in profit. "
      ],
      "metadata": {
        "id": "P44VyhCssKua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 6 : Mean Sales vs Assortment** Means Sales are higher in stores which have assortments of Type b. "
      ],
      "metadata": {
        "id": "ncZSizW4sNMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 7 : Mean Sales vs CompetitionOpenSinceMonth** There isn't much variation in Mean Sales with CompetitionOpenSinceMonth. "
      ],
      "metadata": {
        "id": "X7z6DtzisMF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 8 : Mean Sales vs CompetitionOpenSinceYear** We can observe that there is gradual decrease in mean sales as new competition has opened in recent years."
      ],
      "metadata": {
        "id": "MP01gG_osOkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 9 : Mean Sales vs Promo2** There seems to be a negetive effect on Sales where stores continued to do promotions."
      ],
      "metadata": {
        "id": "reavU60ksQIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 10 : Mean Sales vs Promo2sinceweek** There seems to be no pattern between Promo2sinceweek and mean sales."
      ],
      "metadata": {
        "id": "W-Q4eyl-sRZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 11 : Mean Sales vs Promo2sinceweek** We can observe a gradual decrease in sales from 2009 to uptil 2013,then there is a slight bump at 2014 then again decrease in sales at 2015."
      ],
      "metadata": {
        "id": "7UmXTOoc6ZD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 12 : Mean Sales vs Promointerval**  When promotions are run from the start of the year (january)...we can obtain higher sales in (jan-oct) interval"
      ],
      "metadata": {
        "id": "Fof0BCnV7CcW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 13 : Mean Sales vs year** Means sales have increased over the years."
      ],
      "metadata": {
        "id": "wnnqOz8O7zrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph 14 : Mean Sales vs Promo2sinceweek** Mean sales are higher towards the end of the year.mainly in Oct, Nov and Dec. "
      ],
      "metadata": {
        "id": "rEBh3d5L8GiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check the relationship between store type, assortment levels and sales\n",
        "sns.barplot(x=data[\"StoreType\"],y=data['Sales'],hue=df[\"Assortment\"])"
      ],
      "metadata": {
        "id": "VlwebWFSy27l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the bar graph above We can observe that Assortment type b is only availaible in store type b.\n",
        "\n",
        "In storetype b , assortment c yields greater mean sales and can be used to extract profit if it is in large quantities."
      ],
      "metadata": {
        "id": "ZudCg9I-9Pkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.factorplot(data = df, x =\"Month\", y = \"Sales\",\n",
        "               col = 'StoreType' ,\n",
        "               hue ='Promo',\n",
        "               row = \"Year\"\n",
        "             )"
      ],
      "metadata": {
        "id": "72fI2WKi0PNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every type of store has the same kind of trend throughout the year. Sales are generally increased towards the end of the year."
      ],
      "metadata": {
        "id": "vBj2T4zb_It6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Year and Month columns into a single date column\n",
        "data['Date'] = pd.to_datetime(data['Year'].astype(str) + '-' + data['Month'].astype(str) + '-1')\n",
        "\n",
        "# Group the data by year and month and compute the total sales for each group\n",
        "sales_by_year_month = df.groupby(['Year', 'Month'])['Sales'].sum()\n",
        "\n",
        "# Create a figure and axis for the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# Loop through each year and plot the monthly sales as a line on the same axis\n",
        "for year in sales_by_year_month.index.levels[0]:\n",
        "    sales_by_month = sales_by_year_month.loc[year]\n",
        "    ax.plot(sales_by_month.index, sales_by_month.values, label=str(year))\n",
        "\n",
        "# Add axis labels and a legend to the plot\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_ylabel('Total Sales')\n",
        "ax.set_title('Monthly Sales Over Time by Year')\n",
        "ax.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6fDzuRv-YGaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The time frame between 10-12 month period is where we can expect increase in sales. "
      ],
      "metadata": {
        "id": "nobhJ1lG_2Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns\n"
      ],
      "metadata": {
        "id": "a-pmtsENOUsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_columns = [ 'DayOfWeek', 'Sales', 'Customers',  'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Year', 'Month', 'WeekOfYear',  'DayOfYear']\n",
        "        \n",
        " # Create a correlation matrix of the numerical columns\n",
        "correlation_matrix = data[num_columns].corr()\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(correlation_matrix, annot=True)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Correlation Heatmap')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()      \n",
        "     "
      ],
      "metadata": {
        "id": "xqlVkgMqOiHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HYPOTHESIS TESTING "
      ],
      "metadata": {
        "id": "9y_BUE5TSMix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) The effect of promotions on sales: We are testing whether there is a significant difference in sales between days when there is a promotion versus days when there is no promotion.**\n",
        "\n",
        "Null hypothesis: There is no significant difference in sales between stores with and without a promotion.\n",
        "\n",
        "Alternative hypothesis: Stores with a promotion have significantly higher sales than stores without a promotion."
      ],
      "metadata": {
        "id": "4BXOMIObSWKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.copy()"
      ],
      "metadata": {
        "id": "pFjpOWFQVqf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Filter the data to include only days with promotions and non-promotions\n",
        "promo_sales = df[df['Promo']==1]['Sales']\n",
        "nonpromo_sales = df[df['Promo']==0]['Sales']\n",
        "\n",
        "# Test for difference in means using two-sample t-test\n",
        "t, p = stats.ttest_ind(promo_sales, nonpromo_sales, equal_var=False)\n",
        "print('t-value: {:.2f}, p-value: {:.4f}'.format(t, p))"
      ],
      "metadata": {
        "id": "taxkHKhfS8k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\n",
        "The effect of competition on sales: We are testing whether there is a significant correlation between the distance to the nearest competitor and sales**\n",
        "\n",
        "Null hypothesis: There is no significant relationship between competition distance and store sales.\n",
        "\n",
        "Alternative hypothesis: Stores located closer to competitors have significantly lower sales than stores located farther away."
      ],
      "metadata": {
        "id": "ns1MGbbaVKKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Calculate the Pearson correlation coefficient and p-value between sales and competition distance\n",
        "corr, p = pearsonr(df['Sales'], df['CompetitionDistance'])\n",
        "print('Correlation coefficient: {:.2f}, p-value: {:.4f}'.format(corr, p))"
      ],
      "metadata": {
        "id": "DCakZnanPOeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The effect of store type on sales: You could test whether there is a significant difference in sales between different types of stores.**\n",
        "\n",
        "Null hypothesis: There is no significant difference in sales between different store types.\n",
        "\n",
        "Alternative hypothesis: Some store types have significantly higher sales than others."
      ],
      "metadata": {
        "id": "YN3rOm0jUvdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Filter the data to include only the three store types\n",
        "store_a_sales = df[df['StoreType']=='a']['Sales']\n",
        "store_b_sales = df[df['StoreType']=='b']['Sales']\n",
        "store_c_sales = df[df['StoreType']=='c']['Sales']\n",
        "\n",
        "# Test for difference in means using one-way ANOVA\n",
        "f, p = f_oneway(store_a_sales, store_b_sales, store_c_sales)\n",
        "print('F-value: {:.2f}, p-value: {:.4f}'.format(f, p))"
      ],
      "metadata": {
        "id": "j6BTi1GUVkNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### feature manipulation"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.copy()"
      ],
      "metadata": {
        "id": "vgeicBkScreB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert CompetitionOpenSinceMonth column to integer data type\n",
        "df1['CompetitionOpenSinceMonth'] = df1['CompetitionOpenSinceMonth'].astype(int)\n",
        "\n",
        "# Convert CompetitionOpenSinceYear column to integer data type\n",
        "df1['CompetitionOpenSinceYear'] = df1['CompetitionOpenSinceYear'].astype(int)"
      ],
      "metadata": {
        "id": "uB283QKEcwsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changing promo2 features into meaningful inputs\n",
        "#combining promo2 to total months\n",
        "df1['Promo2Open'] = (df1['Year'] - df1['Promo2SinceYear'])*12 + (df1['WeekOfYear'] - df1['Promo2SinceWeek'])*0.230137\n",
        "\n",
        "#correcting the neg values\n",
        "df1['Promo2Open'] = df1['Promo2Open'].apply(lambda x:0 if x < 0 else x)*df1['Promo2']\n",
        "\n",
        "#creating a feature for promo interval and checking if promo2 was running in the sale month\n",
        "def promo2running(df):\n",
        "  month_dict = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
        "  try:\n",
        "    months = df1['PromoInterval'].split(',')\n",
        "    if df1['Month'] and month_dict[df1['Month']] in months:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  except Exception:\n",
        "    return 0\n",
        "\n",
        "#Applying \n",
        "df1['Promo2Open'] = df1.apply(promo2running,axis=1)*df1['Promo2']\n",
        "\n",
        "#Dropping unecessary columns\n",
        "df1.drop(['Promo2SinceYear','Promo2SinceWeek'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "oLdhDdOodIBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bin edges and labels\n",
        "bin_edges = [0, 500, 1500, 3000, 5000, np.inf]\n",
        "bin_labels = ['near', 'medium', 'far', 'very far', 'extreme']\n",
        "\n",
        "# Create the CompetitionDistanceGroup column\n",
        "df1['CompetitionDistanceGroup'] = pd.cut(df1['CompetitionDistance'], bins=bin_edges, labels=bin_labels)\n",
        "\n",
        "# Show the first 5 rows of the new column\n",
        "print(df1[['CompetitionDistance', 'CompetitionDistanceGroup']].head())"
      ],
      "metadata": {
        "id": "lTPMSCY-dJHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This will create a new column in the dataframe called 'AvgSalesPerCustomer', which will contain the average sales per customer for each store.\n",
        "df1['AvgSalesPerCustomer'] = df1['Sales'] / df1['Customers']"
      ],
      "metadata": {
        "id": "jccf6vQcdX8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in the AvgSalesPerCustomer column with the mean\n",
        "df1['AvgSalesPerCustomer'].fillna(df1['AvgSalesPerCustomer'].mean(),inplace = True)"
      ],
      "metadata": {
        "id": "DR_KAkz1dddg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ENCODING"
      ],
      "metadata": {
        "id": "HkVG1Yswe980"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating variable which stores feature names.\n",
        "X_features = [ 'Store', 'DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo',\n",
        "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
        "        'CompetitionOpenSinceMonth','CompetitionOpenSinceYear', 'Promo2', 'PromoInterval', 'Year', 'Month',\n",
        "       'WeekOfYear', 'DayOfYear', 'Promo2Open', 'CompetitionDistanceGroup',\n",
        "       'AvgSalesPerCustomer'\n",
        "          ]"
      ],
      "metadata": {
        "id": "faV_V1PLuufT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the categorical features to be one-hot encoded\n",
        "categorical_features = ['StoreType', 'Assortment', 'PromoInterval', 'CompetitionDistanceGroup']\n",
        "\n",
        "# Use Pandas get_dummies() function to perform one-hot encoding on the selected categorical features\n",
        "encoded_df = pd.get_dummies(df1[X_features], columns=categorical_features, drop_first=True)\n",
        "\n",
        "# The encoded_df DataFrame now has one-hot encoded columns for each of the selected categorical features\n",
        "encoded_df.head()"
      ],
      "metadata": {
        "id": "p1itHyehAQAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = encoded_df.copy()"
      ],
      "metadata": {
        "id": "5pPceskWRaXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing feature names in index variable.\n",
        "index = ['Store', 'DayOfWeek','Customers', 'Open', 'Promo',\n",
        "       'StateHoliday', 'SchoolHoliday', 'CompetitionOpenSinceMonth',\n",
        "       'CompetitionOpenSinceYear', 'Promo2', 'Year', 'Month', 'WeekOfYear',\n",
        "       'DayOfYear', 'Promo2Open', 'AvgSalesPerCustomer', 'StoreType_b',\n",
        "       'StoreType_c', 'StoreType_d', 'Assortment_b', 'Assortment_c',\n",
        "       'PromoInterval_Feb,May,Aug,Nov', 'PromoInterval_Jan,Apr,Jul,Oct',\n",
        "       'PromoInterval_Mar,Jun,Sept,Dec', 'CompetitionDistanceGroup_medium',\n",
        "       'CompetitionDistanceGroup_far', 'CompetitionDistanceGroup_very far',\n",
        "       'CompetitionDistanceGroup_extreme']"
      ],
      "metadata": {
        "id": "d5yC43UainoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a constant term to the feature matrix for the intercept\n",
        "X = sm.add_constant(X_features)\n",
        "\n",
        "# Set the target variable\n",
        "Y = df2['Sales']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "Hw9QL7DQ1Asj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit OLS regression model\n",
        "model_1 = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print summary of model results\n",
        "model_1.summary2()"
      ],
      "metadata": {
        "id": "RPVkGHDl1wBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HANDLING MULTI-COLLINEARITY**"
      ],
      "metadata": {
        "id": "L6OnpN1E-s9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vif_factors(X):\n",
        "  X_matrix = X.to_numpy()\n",
        "  vif = [ variance_inflation_factor(X_matrix,i) for i in range(X.shape[1])]\n",
        "  vif_factors = pd.DataFrame()\n",
        "  vif_factors['column'] = X.columns\n",
        "  vif_factors['vif'] = vif\n",
        "\n",
        "  return vif_factors"
      ],
      "metadata": {
        "id": "TDfSac-k-1cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vif_factors = get_vif_factors(df2[index])\n",
        "vif_factors"
      ],
      "metadata": {
        "id": "oEC1EGuB-sNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHECKING CORRELATION OF COLUMNS WITH LARGE VIFs**"
      ],
      "metadata": {
        "id": "Z5tJP7sMA8fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "columns_with_large_vif =['PromoInterval_Feb,May,Aug,Nov','PromoInterval_Jan,Apr,Jul,Oct','PromoInterval_Mar,Jun,Sept,Dec']"
      ],
      "metadata": {
        "id": "04SQiicvA7CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then plotting the heatmap for features with VIF more than 4"
      ],
      "metadata": {
        "id": "01_x-TtgB884"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,10))\n",
        "sns.heatmap(df2[columns_with_large_vif].corr(),annot = True)\n",
        "plt.title(\" Heatmap depicting correlation between features\")"
      ],
      "metadata": {
        "id": "rrn1lNhSB8lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df2[df2['Open']==1]"
      ],
      "metadata": {
        "id": "F-2k8_BaDzkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "x = sm.add_constant(df3[index])\n",
        "y = df3['Sales']\n",
        "x_train, x_test,y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "60RTIF3Ll-tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "#x_train = x_train[X_new_features]\n",
        "model_2 = sm.OLS(y_train,x_train).fit()\n",
        "model_2.summary2()"
      ],
      "metadata": {
        "id": "CKQaA3cIE1jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESIDUAL ANALYSIS**"
      ],
      "metadata": {
        "id": "pHgPX4yQN4-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test for Normality of Residuals(P-P plot)"
      ],
      "metadata": {
        "id": "p4AX7g1OPr9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_pp_plot(model,title):\n",
        "  probplot = sm.ProbPlot(model.resid)\n",
        "  plt.figure(figsize = (8,6))\n",
        "  probplot.ppplot(line='45')\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "K5j4Cq7od0on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_pp_plot(model_2,\"Normal P-P Plot of Regression Standardized Residuals\")"
      ],
      "metadata": {
        "id": "YJYH6kNuPBcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Residual Plot for Homoscedasticity and Model Specification "
      ],
      "metadata": {
        "id": "rSMQEx8dQN1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_standardized_values(vals):\n",
        "  return (vals - vals.mean())/vals.std()"
      ],
      "metadata": {
        "id": "XXBL3PnSRkN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_resid_fitted(fitted,resid,title):\n",
        "  plt.scatter(get_standardized_values(fitted),get_standardized_values(resid))\n",
        "  plt.title(title)\n",
        "  plt.xlabel(\"Standardized predicted values\")\n",
        "  plt.ylabel(\"Standardized residuals values\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "MJxIygjkP3K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_resid_fitted(model_2.fittedvalues,model_2.resid,\"Residual Plot\")"
      ],
      "metadata": {
        "id": "iotuY-1wRFeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Section"
      ],
      "metadata": {
        "id": "2WVLhO9HYe5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "y_train = np.sqrt(y_train)"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = sm.OLS(y_train,x_train).fit()\n"
      ],
      "metadata": {
        "id": "TbNOQ00yT7M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary2()"
      ],
      "metadata": {
        "id": "MaaBEZOLUTjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_pp_plot(model_3,\"Normal P-P Plot of Regression Standardized Residuals\")"
      ],
      "metadata": {
        "id": "ftN1FFiOUkG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3['Sales'] = np.sqrt(df3['Sales'])"
      ],
      "metadata": {
        "id": "OpdSRBJIqBb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(x=df3['Sales'])"
      ],
      "metadata": {
        "id": "Yi9jSPATrQZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OUTLIER DETECTION**"
      ],
      "metadata": {
        "id": "WqMVvUPwrlMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore "
      ],
      "metadata": {
        "id": "t2p6M6UurrLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df3.copy()"
      ],
      "metadata": {
        "id": "-Jq2QSPqsSsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4['zscore'] = zscore(df4['Sales'])"
      ],
      "metadata": {
        "id": "NpzhVlU8rk3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4[(df4['zscore']>3.0) | (df4['zscore']<-3)]"
      ],
      "metadata": {
        "id": "3SMv00VFskpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_outliers = df4[~((df4['zscore']>3.0) | (df4['zscore']<-3))]"
      ],
      "metadata": {
        "id": "bAmHxUa2tYi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = df_no_outliers.drop('zscore', axis=1)\n"
      ],
      "metadata": {
        "id": "_A82pEjwt5k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5.columns"
      ],
      "metadata": {
        "id": "75w3EN3tu4jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler "
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index =['Store', 'DayOfWeek', 'Customers', 'Open', 'Promo',\n",
        "       'StateHoliday', 'SchoolHoliday', 'CompetitionOpenSinceMonth',\n",
        "       'CompetitionOpenSinceYear', 'Promo2', 'Year', 'Month', 'WeekOfYear',\n",
        "       'DayOfYear', 'Promo2Open', 'AvgSalesPerCustomer', 'StoreType_b',\n",
        "       'StoreType_c', 'StoreType_d', 'Assortment_b', 'Assortment_c',\n",
        "       'PromoInterval_Feb,May,Aug,Nov', 'PromoInterval_Jan,Apr,Jul,Oct',\n",
        "       'PromoInterval_Mar,Jun,Sept,Dec', 'CompetitionDistanceGroup_medium',\n",
        "       'CompetitionDistanceGroup_far', 'CompetitionDistanceGroup_very far',\n",
        "       'CompetitionDistanceGroup_extreme']"
      ],
      "metadata": {
        "id": "Y8Mdg5wLu-Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing the StandardScaler\n",
        "X_scaler = StandardScaler()\n",
        "#Standardizie all the feature columns \n",
        "X_scaled = X_scaler.fit_transform(df5[index])\n",
        "\n",
        "#Standardizing Y by explicitly by substracting mean and divding by standard deviation\n",
        "Y = (df5['Sales']-df5['Sales'].mean())/df5['Sales'].std()"
      ],
      "metadata": {
        "id": "v-Qwemp8qm-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "x_train,x_test,y_train,y_test = train_test_split(X_scaled,Y,test_size = 0.2,random_state = 42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calculate_metrics(model_name, model, x_train, x_test, y_train, y_test):\n",
        "   \n",
        "    # Make predictions on the training and test sets\n",
        "    y_train_pred = model.predict(x_train)\n",
        "    y_test_pred = model.predict(x_test)\n",
        "\n",
        "    # Calculate the metrics\n",
        "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    n = len(y_train)\n",
        "    k = x_train.shape[1]  # number of independent variables\n",
        "    train_adj_r2 = 1 - ((1 - train_r2) * (n - 1) / (n - k - 1))\n",
        "\n",
        "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "    test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    n = len(y_test)\n",
        "    k = x_test.shape[1]  # number of independent variables\n",
        "    test_adj_r2 = 1 - ((1 - test_r2) * (n - 1) / (n - k - 1))\n",
        "\n",
        "    data = {\n",
        "        'Model_Name': [model_name],\n",
        "        'Train_MAE': [train_mae],\n",
        "        'Train_MSE': [train_mse],\n",
        "        'Train_RMSE': [train_rmse],\n",
        "        'Train_R2': [train_r2],\n",
        "        'Train_Adj_R2': [train_adj_r2],\n",
        "        'Test_MAE': [test_mae],\n",
        "        'Test_MSE': [test_mse],\n",
        "        'Test_RMSE': [test_rmse],\n",
        "        'Test_R2': [test_r2],\n",
        "        'Test_Adj_R2': [test_adj_r2]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "3_pt7EAIfODc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge, Lasso"
      ],
      "metadata": {
        "id": "aFfc31Pjwq_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge()\n",
        "ridge.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "0KoaTR7Tepa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.coef_"
      ],
      "metadata": {
        "id": "BYA4Xo5ue8vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate RMSE and R2 score**"
      ],
      "metadata": {
        "id": "teS84nzxf__U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_1 = calculate_metrics('ridge regression',ridge,x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "L_luB_1Kh34U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_1"
      ],
      "metadata": {
        "id": "U5LPDuHbCLpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the evaluation metrics provided, it seems like the linear regression model is performing well on both the training and test sets.\n",
        "\n",
        "The RMSE values of 0.263 for the training set and 0.261 for the test set indicate that the model's predictions are on average around 0.26 units away from the actual target values in both the training and test sets. Lower RMSE values generally indicate better model performance.\n",
        "\n",
        "The R-squared (R²) score is a metric that indicates how well the model fits the data. The R² score ranges from 0 to 1, with higher values indicating better fit. The R² score of 0.931 for the training set and 0.932 for the test set suggest that the model explains a large proportion of the variance in the target variable, both in the training and test sets.\n",
        "\n",
        "Overall, the RMSE and R² score suggest that the linear regression model is performing well and making accurate predictions on both the training and test sets, without overfitting to the training data. "
      ],
      "metadata": {
        "id": "e5OFBKGujWi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ridge.predict(x_test)"
      ],
      "metadata": {
        "id": "hz-tRf9fynuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create distribution plot\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.kdeplot(y_test, label='Actual Values')\n",
        "sns.kdeplot(y_pred, label='Predicted Values')\n",
        "plt.xlabel('Target Value')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution Plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7oDLcOylsOlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, make_scorer"
      ],
      "metadata": {
        "id": "vH3FtTeoEZvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge()\n",
        "params = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'normalize': [True, False]\n",
        "}"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_cv = GridSearchCV(ridge, params, cv=5)\n",
        "ridge_cv.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "4COv0D5-_jzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_best = Ridge(**ridge_cv.best_params_)\n",
        "ridge_best.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "8aRn8r-B_qO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_2 = calculate_metrics('Ridge REgression',ridge_best,x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "oIrO6ZJ6_tjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_2"
      ],
      "metadata": {
        "id": "u0LNLkWgChgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the mean RMSE was found to be 0.26, with a standard deviation of 0.05. This suggests that the model's performance is consistent across different subsets of the data, as the RMSE values obtained through cross-validation are not too different from the original RMSE values obtained on the train and test sets."
      ],
      "metadata": {
        "id": "It_ThFhBtBuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again after cross validation and hyperparameter tuning ,Based on the evaluation metrics provided, it seems like the linear regression model is performing well on both the training and test sets.\n",
        "\n",
        "The RMSE values of 0.263 for the training set and 0.261 for the test set indicate that the model's predictions are on average around 0.26 units away from the actual target values in both the training and test sets. Lower RMSE values generally indicate better model performance.\n",
        "\n",
        "The R-squared (R²) score is a metric that indicates how well the model fits the data. The R² score ranges from 0 to 1, with higher values indicating better fit. The R² score of 0.931 for the training set and 0.932 for the test set suggest that the model explains a large proportion of the variance in the target variable, both in the training and test sets.\n",
        "\n",
        "Overall, the RMSE and R² score suggest that the linear regression model is performing well and making accurate predictions on both the training and test sets, without overfitting to the training data."
      ],
      "metadata": {
        "id": "JyT2eFrDxtND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "#rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "#rf_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = { \"Model_Name\":'RandomForestRegressor',\"Train_MAE\":0.000619,\"Train_MSE\":0.000005,\"Train_RMSE\":0.002225,\"Train_R2\":0.999995,\"Train_Adj_R2\": 0.999995,\"Test_MAE\":0.001475,\"Test_MSE\": 0.000041,\"Test_RMSE\": 0.006436,\"Test_R2\": 0.999958,\"Test_Adj_R2\":0.999908}"
      ],
      "metadata": {
        "id": "pF8ygvHrHzJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_3 = pd.DataFrame(data,index=[0])"
      ],
      "metadata": {
        "id": "5IlTsLdEMjR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_3"
      ],
      "metadata": {
        "id": "a3g70GHr8Dhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BcuJ0-E9AgmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we can create a RandomForestRegressor object and define a set of hyperparameters to tune\n",
        "#rf = RandomForestRegressor(random_state=42)\n",
        "#params = {\n",
        "#    'n_estimators': [10, 50, 100],\n",
        "#    'max_depth': [5, 10, None],\n",
        "#    'max_features': ['sqrt', 'log2', 0.5]\n",
        "#}\n",
        "\n",
        "#We'll use GridSearchCV to search over these hyperparameters to find the best set of hyperparameters. We'll specify the number of folds for cross-validation using the cv parameter\n",
        "#rf_cv = GridSearchCV(rf, params, cv=5)\n",
        "#rf_cv.fit(X_train, y_train)\n",
        "\n",
        "#Now we can use the best hyperparameters to train a RandomForestRegressor model on the entire training set\n",
        "#rf_best = RandomForestRegressor(**rf_cv.best_params_, random_state=42)\n",
        "#rf_best.fit(X_train, y_train)\n",
        "\n",
        "#metrics_4 = calculate_metrics(\"RandomForest_cross_validated\",rf_best,x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "Kdey7VRGNCEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "lasso.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.coef_"
      ],
      "metadata": {
        "id": "kla43XKEpEgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_5 = calculate_metrics('Lasso regression',lasso,x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "0IroOxsnpceU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_5"
      ],
      "metadata": {
        "id": "3JzKr_oTpotI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "params = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'normalize': [True, False]\n",
        "}"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_cv = GridSearchCV(lasso, params, cv=5)\n",
        "lasso_cv.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "lDetkb-nqG82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_best = Lasso(**lasso_cv.best_params_)\n",
        "lasso_best.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "5x3gFzivqgdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_6 = calculate_metrics('Lasso REgression',lasso_best,x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "Kx-TavaVqoOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_6"
      ],
      "metadata": {
        "id": "dMRV6L05qz9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8QgxgVOANZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "linear regression\n"
      ],
      "metadata": {
        "id": "Fwk-Wn2nAesM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap==0.40.0\n",
        "import shap \n",
        "import graphviz\n",
        "sns.set_style('darkgrid') \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "JqyyehQlFeum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the explainability tool\n",
        "explainer = shap.LinearExplainer(ridge, x_train)\n",
        "\n",
        "# Calculate the SHAP values for the test data\n",
        "shap_values = explainer.shap_values(x_test)\n",
        "\n",
        "# Plot the summary plot to show the feature importance\n",
        "shap.summary_plot(shap_values, x_test, feature_names=index)\n"
      ],
      "metadata": {
        "id": "mHVQUGeu_KEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "ZLs9kBhWAhox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linreg = LinearRegression()\n",
        "linreg.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "B0-YZqjPAr0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The dataframe has two columns to store feature name and the corresponding coefficient values \n",
        "columns_coef_df = pd.DataFrame({'columns': df5[index].columns,'coef':linreg.coef_})\n",
        "\n",
        "#Sorting the features by coefficient values in descending order \n",
        "sorted_coef_vals = columns_coef_df.sort_values('coef',ascending = False)"
      ],
      "metadata": {
        "id": "_6vngX8fvUtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_df = pd.concat([metrics_2,metrics_3,metrics_6])"
      ],
      "metadata": {
        "id": "0lD2ZblhAoBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_df"
      ],
      "metadata": {
        "id": "VbvDBcspD_Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}